% !TEX root = ../main.tex

\chapter{系统实现}
\label{ch:implementation}

第三章详细阐述了模拟器在在线调度场景中的核心设计，及其与离线模拟器在状态管理和预测演进过程中的区别，包括状态同步机制和状态演进管理。
本章则介绍性能预测组件及预测器在大模型服务集群中的具体实现细节。本文使用Rust作为实现语言，基于其无垃圾回收的高性能和强大的异步并发库，以满足在线服务场景请求调度关键路径中性能预测组件的高效性和可靠性要求，
利用Tokio运行时实现高效的并发控制，以对多个实例进行并发性能预测。系统在全局调度器中集成性能预测组件，并与vLLM推理引擎进行集成。

\section{核心数据结构}

\section{性能预测器}
在模拟器的状态管理之外，性能预测器是保证预测准确性的另一关键组件，并且需要选用延迟低的方式预测。本文采用与Vidur类似的离线性能剖析和预测、运行时查表根据相结合的方式进行性能预测。

具体来说，离线性能剖析过程时，针对模型的结构构建特定的批次，送入对应模型进行前向传播，捕捉得到每个部分的执行时长。后续预测过程中对每个部分加载性能剖析得到的执行时长，并构建选定特征与执行时长映射的预测表，通过随机森林对预测表中的缺省值进行预测和填充，这样得到一张相对稠密的预测表。
运行时只需要加载每个部分的预测表，根据模拟器组建出的批特征值查找预测表中的执行时长，即可读取得到模型推理的执行时长。这样的方式将性能剖析、预测这些性能开销较重的过程放在离线进行，在线预测时仅需对给定批处理特征在每个部分的预测表中进行查找，这将在线预测的时延降到了几次内存读取的量级，从而避免成为系统瓶颈。
在特征的选定上，针对特定模型结构的执行行为采用不同的特征来映射执行时长，要控制对每个组件仅使用一到两个特征，来避免特征过多导致预测表过大。
对于执行逻辑较简单的模块如矩阵相乘(例如KV Projection, MLP等模型结构)，执行时长仅与批次包含的Token数强相关，因此建模的特征只需要包含Token数量。
但对于较为复杂的Attention层，前向推理的执行时长则更为复杂，尤其在PD共置部署下Chunked Prefill和PD混合批的优化大大提高了批处理的复杂度，因为推理时的动态性会构建出Prefill请求数、Decode请求数和各自的KVCache大小都存在差异的批，给性能预测带来更大的挑战。
针对混合批在Attention上的执行特性，将Prefill和Decode核函数的特征分开以简化建模。前者使用KVCache大小和计算量(定义为应用Mask之后Attention算法所需的计算量Chunk\_size * kvcache\_size)，后者使用Batch中请求数和平均KVCache大小，两者分别由特征映射得到执行时间。
这样的建模方式既能够捕捉Prefill和Decode影响执行性能的关键特征，又能避免使用过多特征让构建稠密的预测表和动态查表过程变得不可行。

由于加载的预测数据量较大(TODO!),并且对给定Batch进行性能预测的操作是无状态、只读的，因此性能预测模块仅需一个预测器实例，即加载一次预测数据，
就能够在多个模拟器实例中并发进行性能预测，满足在线调度场景中对多个实例进行性能预测的需求，极大降低了内存开销。
