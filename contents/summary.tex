% !TEX root = ../main.tex

\chapter{总结}
本文针对LLM推理服务中的全局调度场景，基于已有的模拟器和调度策略工作，对性能预测能力在调度决策上的应用进行研究，回答了已有调度策略工作尚未阐明的问题。
具体来说，我们在全局调度器中通过模拟器模拟请求到达实例的执行性能来实现性能预测模块，为调度决策提供时延预测能力。在实现性能预测能力的过程中，本文分析在线调度场景与已有的离线吞吐规划场景中对模拟器的需求不同，并通过状态抽象和预测缓存复用机制保证了性能预测模块的预测准确性和在线可用性。
为了验证基于性能预测的调度策略在LLM服务的性能提升，本文在统一的调度框架上实现了当前在开源社区、学术界和工业界应用的调度策略作为评价基线，与基于性能预测的调度策略对比。
在8实例的推理服务集群上，我们部署Dense和MoE模型并通过请求重放多样化的工作负载得到端到端性能比较结果。
端到端服务性能比较结果表明基于性能预测的调度策略能够避免指标选取、参数调优的复杂过程，并且相对于主流开源框架vLLM的调度策略能够带来至多(TODO!)的性能提升。

对于预测的准确性，本文分别对Dense和MoE请求TTFT预测结果与执行Ground Truth进行对比，发现对于Dense模型，预测误差相对较小，有90\%请求的预测误差小于20\%，而对于MoE模型，预测误差相对较大，小于20\%误差的请求仅占60\%。
并且通过在相同状态下不同模拟器指派结果统计Spearman系数，发现模拟器能够一定程度存在跨模型的迁移能力，即通过使用Qwen3-30B-A3B的预测表预测Qwen2.5-7B的请求TTFT，在一次请求重放中能够达到(TODO!)的决策相同。作为对比，与其他调度策略的spearman系数仅为(TODO!)。
这意味着对于一个模型性能剖析得到的模拟器，同样能够为其他模型提供性能预测能力，并在相同工作负载请求重放测试下达到(TODO!)的TTFT Mean性能。
此外，本文还进行了模拟器组件的吞吐测试，验证了即使在64实例的大型推理服务集群上，模拟器作为性能预测组件仍然能够保证不会成为系统瓶颈，以(TODO!)工作负载为例，模拟器的吞吐能够达到(TODO!)QPS,大于系统服务能力的(TODO!)QPS，为模拟器在大规模推理服务集群进行调度决策指导提供了保证。

虽然本文实现了用于请求调度决策的推理性能模拟器，并达到了(TODO!)的准确度，但是由于模拟器对执行时长建模的不足、以及分布式系统组件之间的固有缺陷(在Section5中提到的)，预测准确性仍然有一定的提升空间。未来的工作中可以分析，更高精准度的在线模拟器是否能够进一步提高集群服务能力。
并且本文受限于硬件资源限制，无法对当前越来越成为主流、参数量更大的大型MoE模型进行性能预测和端到端性能测试，未来可以考虑增大硬件资源以对这些大型MoE模型分析性能预测能力及其对服务能力的影响。



