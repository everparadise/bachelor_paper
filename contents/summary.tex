% !TEX root = ../main.tex

\chapter{总结}
本文针对LLM推理服务中的全局调度场景，基于已有的模拟器和调度策略工作，设计实现了用于在线调度场景的模拟器提供调度时的性能预测能力，并对性能预测能力对系统服务能力的影响进行研究，回答了已有调度策略工作对如何实现在线性能预测能力、性能预测能力的有效性等尚未阐明的问题。
在系统设计上，我们在全局调度器中通过模拟器模拟请求到达实例的执行性能来实现性能预测组件，为调度决策提供执行性能预测能力。本文分析了在线调度场景与已有的离线吞吐规划场景中对模拟器的不同需求，包括接口语义、状态维护和执行过程，并基于此通过状态抽象和预测缓存复用机制保证了性能预测模块的预测准确性和在线可用性。
对于实验设计，为验证基于性能预测的调度策略在LLM服务性能上的提升，本文在统一的调度框架上实现了多种调度策略以排除系统实现对服务能力的影响，实现的基线策略包括当前在开源社区、学术界和工业界应用的调度策略，在与本文基于性能预测的调度策略进行比较。本文基于多样的工作负载(Qwen ChatBot, Qwen Coder, Qwen Agent和Kimi ToolAgent)进行请求重放和端到端测试以覆盖不同的LLM应用场景。
在8张H20的推理服务集群上，我们使用广泛部署的Qwen2.5-7B(Dense)和Qwen3-30B-A3B(MoE)模型作为服务模型，在vLLM-v1上。
端到端服务性能比较结果表明基于性能预测的调度策略能够避免指标选取、参数调优的复杂过程，并且相对于主流LLM服务开源框架vLLM的调度策略能够带来至多(TODO!)的TTFT Mean提升，只牺牲(TODO!)的TPOT性能。

对于预测的准确性，本文分别将两种服务模型的TTFT预测结果与真实执行性能进行对比，验证了对于模型，预测误差相对较小，有90\%请求的预测误差小于20\%，而对于MoE模型，预测误差相对较大，小于20\%误差的请求仅占60\%。
在跨表预测的分析中，基于相同状态下不同模拟器的指派结果统计Spearman系数和比较端到端性能，发现模拟器存在跨模型的迁移能力，即使用与服务模型不同的预测表指导调度，在请求重放中能够达到(TODO!)的决策相同，并在相同工作负载请求重放测试下达到(TODO!)的TTFT Mean性能。
此外，本文在受限硬件环境中进行模拟器组件的可扩展性测试，验证了即使在64实例的大型推理服务集群上，模拟器作为性能预测组件仍然能够保证不会成为系统瓶颈，为模拟器在大规模推理服务集群进行调度决策指导提供了保证。

虽然本文实现了用于请求调度决策的推理性能模拟器，并达到了(TODO!)的准确度，但是由于模拟器对执行时长建模的不足、以及分布式系统组件之间的固有缺陷(在Section5中提到的)，预测准确性仍然有一定的提升空间。未来的工作中可以分析，更高精准度的在线模拟器是否能够进一步提高集群服务能力。
并且本文受限于硬件资源限制，无法对当前越来越成为主流、参数量更大的大型MoE模型进行性能预测和端到端性能测试，未来可以考虑增大硬件资源以对这些大型MoE模型分析性能预测能力及其对服务能力的影响。



