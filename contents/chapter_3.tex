% !TEX root = ../main.tex

\chapter{在线模拟器设计}
\label{ch:design}

离线模拟器是LLM服务系统设计与容量规划的重要工具。给定完整的请求trace和系统配置，
离线模拟器在CPU上步进执行，输出吞吐、时延等性能指标，以评估不同配置的效果。
这类模拟器的运行环境是单机的，状态确定性的线性发展，没有实时性要求。
而在线调度场景的性能预测能力对模拟器提出了完全不同的需求，
模拟器需要在每个请求到达时，快速得到请求在当前实例的执行性能，
即回答“如果将当前请求发往实例i，它的TTFT会是多少？”这样的反事实问题。
这要求模拟器以在线服务的方式运行，与推理实例分布式部署和状态同步，
对请求预测能够实时响应，并达到微秒级预测延迟。

将离线模拟器直接用于在线调度面临三个根本性差异。

第一，接口和语义不同。离线模拟器通常提供批处理接口：
输入trace文件，输出性能报告。而在线调度需要的是低延迟的查询接口，
能够为每个到达的请求并行查询多个实例，并在微秒级返回预测结果。

第二，状态维护不同。离线模拟器中，模拟器完全决定实例状态，
所有信息都在单进程内同步更新。在线场景中，调度器和实例是分布式部署的，
并且实例调度器为了优化吞吐、公平性等目标，
正在采用越来越复杂的设计——优先级抢占、动态批处理、分块预填充、请求优先级队列。
这些行为为调度引入了不确定性和复杂性，也为模拟器状态同步带来了挑战。

第三，执行过程不同。在线调度需要回答的是“如果把这个请求发过去会怎样”。
这是反事实的执行过程，需要在当前已经发生的状态之上，叠加一个尚未发生的请求，
向前模拟直到该请求产出首token。
这要求模拟器具备“快照”能力：能够基于当前状态创建假设分支，
在不影响真实状态的情况下执行模拟。

\section{状态同步机制}

忽略由生成Token的不同带来的随机性，常见的实例调度器批处理行为通常是确定的，即在相同的状态下能够构造出完全相同的批，从而得到相近的执行时间，这是模拟器能够对LLM实例或集群推理性能进行相对准确预测的前提。

在离线模拟器中，通过在给定Workload中包含请求生成长度、生成Token信息和请求到达时间信息来排除请求到达和生成Token的随机性。
在预测过程中，由模拟器完全决定实例状态。具体来说，执行队列、等待队列和KVCache等状态由模拟器管理，
并随事件循环的时间推进而模拟调度执行和状态更新。这意味这状态管理是确定性线性推进的。
而在在线场景中，全局调度器和推理实例是分离的组件，由全局调度器维护每个实例的状态镜像，
为了保证性能预测的准确，需要保证两者基于相同的状态。

\subsection{状态同步的必要性}
推理实例根据动态生成的Token控制请求终止(例如EOF或用户指定的终止字符)，
推理实例比全局调度器包含更多确定性信息，模拟器需要同步推理实例的最新状态来消除不确定性。

并且实例调度器正在变得越来越智能，一些研究工作引入了优先级抢占、请求暂停与恢复、公平性队列等更复杂的行为。
这些行为在实例内部是确定性的，但从外部观察，全局调度器很难仅凭自管的信息来还原实例的完整状态和行为。

由于上述在线场景下全局调度器的信息缺失和职责不同，依赖全局调度器去猜测实例的状态变化是不可行的。
需要让实例主动将状态变更和执行行为上报给调度器以实现状态同步机制。

\subsection{同步接口设计}

常见的推理框架通过OpenAI接口接收推理请求，但全局调度器不便于通过OpenAI接口返回的请求信息得知推理实例的执行行为。
因此为推理框架添加新的SSE长连接接口，启动时全局调度器与每个实例建立连接。
在推理实例每次发生影响未来调度的状态变化时，将调度结果、执行结果的关键信息上报给全局调度器。

推理实例状态变化在两个时间点发生：第一是接收到全局调度器指派的新请求并加入请求队列，此时只需要在模拟器中也将新请求添加到请求队列。
第二是推理实例每次批处理结束时,此时需要更为精细的状态上报与更新。
状态上报的设计需要权衡信息量和通信开销。对于完整的状态快照，因为包含所有KVCache的分配信息，信息量由于过于昂贵不可接受。
本文采用增量更新上报的方式：上报的信息只包含自上次上报以来发生变化的部分。
例如，当前批处理包含的请求ID和关键信息（处理长度、新生成的Token以及是否完成）、
KVCache的变化(以vLLM为例，包括新分配的Block ID、对应的Hash和剔除的Block ID)以及特殊事件的记录例如请求抢占等。

而对于全局调度器，则需要根据上报信息更新每个实例的状态镜像，维护请求队列和KVCache状态的镜像。
\subsection{同步机制的代价}
对于推理框架添加同步机制，带来的额外处理和网络开销非常小。
这是因为摘要体积很小，通常只有几十K字节，在推理实例调度和批处理结束状态更新时插桩，对网络和实例处理的开销可以忽略(TODO! 可以测一下实例处理的开销)。
并且状态上报的频率和推理实例的批处理频率相当，以实验的H20机器为例，根据批大小和请求上下文长度不同，上报间隔通常在几十毫秒到几百毫秒之间。
在全局调度器上的平均处理时延为(TODO!),完全能够满足在线调度的需求，不会阻塞调度决策。

状态同步对实例的改动也很小，主要是状态变更点的埋点和添加状态上报的接口，在vLLM中实现状态同步增加约x行代码，。

\section{状态演进管理}
与离线的模拟器不同，在线模拟器的状态存在反事实的预测过程。
每次收到新请求时，模拟器会模拟这个新请求在实例状态上的调度，这会导致实例状态如请求队列、KVCache的改变。
在这个过程并不应影响模拟器维护的真实状态，因为如果该请求没有被指派到该实例，后续请求的预测从正确的状态开始。
因此需要对预测过程中的状态演进进行管理，保证不会影响到真实状态。

\subsection{直接的做法: 独立预测}

最简单直接的做法是：每次收到新请求，都从当前状态S开始，克隆出一份请求队列作为预测状态，完整模拟新请求完成。
如(TODO!)所示，考虑连续到达的三个请求r1、r2、r3。
假设r1到达时状态为S0，我们模拟得到它的TTFT，同时模拟过程会从S0推进到S1（经过若干步）。
如果r2到达时实例状态仍然是S0（r1还在排队，尚未开始执行），按照独立预测的做法，我们要从S0开始模拟r2的执行。
但从S0推进到S1的过程实际上被重复计算了，r1之后若干步的模拟结果本可以被r2复用。

这引出一个关键洞察：当前常见的推理框架的请求调度是遵循先到先服务的，新到达请求需要排在当前请求队列的末尾，
因此新请求的执行状态演进路径必然包含前序未完成请求的演进路径，这为预测复用提供了可能。
预测状态管理应该设计为状态演进式的，即维护一个最新的演进状态，新请求在上一次预测推进后的状态基础上开始预测。

因此每个实例可以维护一个演进状态和批处理队列:演进状态作为对模拟器最新状态的预测，新请求可以直接在演进状态上克隆请求队列开始性能模拟，称为模拟状态，并在模拟调度时将每个得到的批压入批处理队列。
如果请求确认指派到该实例，那么模拟状态就可以作为演进状态并保留批处理队列，实现预测复用。
如果请求没有指派到该实例，那么将模拟状态丢弃，保持演进状态不变，等待下一个请求到来时继续在演进状态上模拟。

预测过程如(TODO!)，在调用\texttt{predict(r)}时，在当前模拟状态上插入r并向前推进，将每一步推进后的状态压栈，累加各步的执行时间得到TTFT。
请求确认指派时将模拟状态作为新的演进状态并保留批处理队列，供后续请求复用。


\subsection{与状态同步的配合}

状态演进式预测依赖于一个假设：预测的状态演进路径，与实例真实的状态演进路径是一致的。但现实中，实例的真实执行可能因为各种原因与预测不同:
实例内部对到达请求进行并行分词，由于分词时长差异导致调度顺序被改变；或者发生请求终止时被推理实例从请求队列中剔除；以及在状态同步章节(TODO! 插入标签)提到的非确定性调度行为等。

通过状态同步机制在这里校准演进状态。当调度器收到推理实例批处理完成后的状态同步时，在\texttt{sync}中与预测批处理队列的头部批进行比对：
如果真实状态与预测状态一致，说明预测是正确的，将栈顶弹出，预测状态与真实状态对齐。
如果真实状态与预测状态不一致，说明预测路径与真实路径发生了偏离。此时清空整个演进状态和批处理队列，将演进状态重置为真实状态。
(TODO 这里给出偏离情况，并讲解偏离时如何更新演进状态)

这种设计将预测视为“提前执行”的模拟，而同步则负责在真实执行发生时进行校准。只要预测与真实的偏离不频繁，预测状态就能保持复用，保证预测的有效性。


\section{语义与架构设计}

在这一部分分析在线模拟器与离线模拟器的语义不同，暴露三个接口，可以对Predict和AddRequest进行设计
此外，讲解架构设计，全局调度器中包含模拟器模块，实例侧包含状态同步模块，二者通过RPC通信实现状态同步和预测查询。

\subsection{接口}

\begin{verbatim}
fn predict(&self, req: &Request, instance_id: InstanceId) -> Result<Duration>
\end{verbatim}

\texttt{predict}是核心预测接口。给定请求r和目标实例i，返回请求r如果发往实例i的预估TTFT。

实现逻辑：
\begin{itemize}
  \item 获取实例i当前维护的预测状态（即上一次预测推进后的最新状态）。
  \item 在预测状态上插入请求r，按照3.4节的演进规则向前模拟，直到r的prefill完成。
  \item 累加各步的执行时间，返回总时间。
  \item 将模拟过程中产生的中间状态（每一步推进后的batch pattern）压入预测状态栈，供后续请求复用。
\end{itemize}

由于调度器需要同时为多个实例进行预测，\texttt{predict}支持并发调用，内部实现无锁，利用Rust的异步运行时并行执行。

\subsection{add\_request}

\begin{verbatim}
fn add_request(&self, req: &Request, instance_id: InstanceId)
\end{verbatim}

\texttt{add\_request}在调度器确认将请求r发往实例i后调用。这个接口的作用是更新模拟状态，让模拟状态“知道”请求r确实已经到达实例i。

为什么需要这个接口？因为\texttt{predict}是反事实的——它预测“如果把请求发过去会怎样”，但请求可能最终没有被发往这个实例。\texttt{add\_request}负责将“反事实”变为“事实”：将请求r正式加入实例i的模拟状态队列。

实现逻辑很简单：将请求r加入实例i的等待队列统计信息中。如果实例i的预测状态栈非空（即已经有一些预测推进），\texttt{add\_request}会将请求r加入最新状态，并从那里开始继续演进。

\texttt{add\_request}与\texttt{predict}配合使用：先\texttt{predict}所有候选实例，选择最优目标，然后对选中的实例调用\texttt{add\_request}确认，对其他实例不做操作（它们的模拟状态保持不变）。

\subsection{sync}

\begin{verbatim}
fn sync(&self, instance_id: InstanceId, state_delta: StateDelta) -> Result<()>
\end{verbatim}

\texttt{sync}由实例回调调用，用于将真实状态变更同步给调度器。\texttt{StateDelta}包含版本号和变更摘要，具体格式在3.2节已描述。

实现逻辑：
\begin{itemize}
  \item 根据版本号判断同步信息的有效性。
  \item 如果版本号连续，将变更摘要应用到模拟状态上。
  \item 同时，将变更摘要与预测状态栈的栈顶进行比较：
    \begin{itemize}
      \item 如果栈顶状态与真实状态一致，弹出栈顶，预测状态与真实状态对齐。
      \item 如果不一致，清空整个预测状态栈，将预测状态重置为真实状态。
    \end{itemize}
\end{itemize}

\texttt{sync}是状态演进式预测能够长期保持有效性的关键。它确保预测不会偏离真实太远，一旦偏离就被及时纠正。


下一章将通过端到端实验，验证本章设计在实际系统中的效果。